{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e878c6-5f7b-42a6-b4a1-6bbdabd84393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was an attempt to get results at a degraded resolution from data we already have, i.e. generating 200m resolution data from 20m resolution data. Ran into issues with file size and memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a9de9-d44f-4b7b-b799-fd4cd224a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import csv\n",
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb41782d-9087-46ce-ab83-e3f11773b0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninputs: file name/location & new resolution in km\\n\\n1. get bounding box from file - DONE\\n2. take bounding box and create list of squares in desired resolution - DONE\\n3. for each new square, find all squares in csv file within the new square - DONE\\n4. take the average of each column for the squares within the new square - write row to new file - DONE\\n5. status - DONE\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "inputs: file name/location & new resolution in km\n",
    "\n",
    "1. get bounding box from file - DONE\n",
    "2. take bounding box and create list of squares in desired resolution - DONE\n",
    "3. for each new square, find all squares in csv file within the new square - DONE\n",
    "4. take the average of each column for the squares within the new square - write row to new file - DONE\n",
    "5. status - DONE\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1129b14f-a6b8-41ce-9873-9ded754b998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"results_bigregion_bottom/compiled.csv\"\n",
    "new_res = .2 # 200 m = .2 km, 20 m = .02 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8565e38-8305-4dd3-a1ca-76f9e48798d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2799/3882818327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#ex = np.genfromtxt(file, delimiter=',', skip_header=1, skip_footer=0, usecols = (0, 1, 2, 3, 7))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_footer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/newEnv/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[1;32m   2072\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2073\u001b[0m             \u001b[0;31m# Store the values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2074\u001b[0;31m             \u001b[0mappend_to_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2075\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0musemask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2076\u001b[0m                 append_to_masks(tuple([v.strip() in m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#ex = np.genfromtxt(file, delimiter=',', skip_header=1, skip_footer=0, usecols = (0, 1, 2, 3, 7))\n",
    "ex = np.genfromtxt(file, delimiter=',', skip_header=1, skip_footer=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e214a125-805b-41ae-8274-6552eaf15daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find bounding box\n",
    "min_lon = np.amin(ex[:,0]);\n",
    "min_lat = np.amin(ex[:,1]);\n",
    "max_lon = np.amax(ex[:,2]);\n",
    "max_lat = np.amax(ex[:,3]);\n",
    "print(min_lon)\n",
    "print(min_lat)\n",
    "print(max_lon)\n",
    "print(max_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf55f54-8ca9-4e39-8b1a-6b7e35bcfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_box = ee.Geometry.Polygon([[[min_lon, min_lat], [min_lon, max_lat], [max_lon, max_lat], [max_lon, min_lat]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d2d0a-b985-48f7-b889-107379abbdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segments(geometry, size):\n",
    "    # grab the top left coordinate of the bounding box\n",
    "    coords = ee.List(geometry.coordinates().get(0)).slice(0, -1)\n",
    "    top = ee.Number(ee.List(coords.get(2)).get(1))\n",
    "    left = ee.Number(ee.List(coords.get(0)).get(0))\n",
    "    top_left_point = ee.Geometry.Point([left, top])\n",
    "    \n",
    "    # calculate square pixel width and height\n",
    "    width = int(ee.Geometry.Point(coords.get(0)).distance(ee.Geometry.Point(coords.get(1))).divide(1000 * size).getInfo()) # how many squares can fit in the width of the bounding box\n",
    "    height = int(ee.Geometry.Point(coords.get(1)).distance(ee.Geometry.Point(coords.get(2))).divide(1000 * size).getInfo()) # how many squares can fit in the height of the bounding box\n",
    "    \n",
    "    # create a point buffer and use it to find the km distance to lat/lon degree conversion\n",
    "    buff = top_left_point.buffer(size*1000, 0.1) # create the buffer with a max % error of 0.1\n",
    "    buff_list = ee.List(buff.coordinates().get(0)) \n",
    "    buff_length = buff_list.length()\n",
    "    right_pt = ee.List(buff_list.get(buff_length.multiply(0.75).int().subtract(1)))\n",
    "    bottom_pt = ee.List(buff_list.get(buff_length.multiply(0.5).int().subtract(1)))\n",
    "    new_lat = ee.Number(right_pt.get(0)) # given distance east of the top left point\n",
    "    new_lon = ee.Number(bottom_pt.get(1)) # given distance south of the top left point\n",
    "    \n",
    "    diff_lon = top.subtract(new_lon) # given size converted to degrees\n",
    "    diff_lat = new_lat.subtract(left)\n",
    "    \n",
    "    # build the list of squares\n",
    "    segments = []\n",
    "    \n",
    "    for y in range(height + 1): # +1 to guarantee we will cover the whole region (squares may extend slightly past the bounding box)\n",
    "        left = ee.Number(ee.List(coords.get(0)).get(0))\n",
    "        for x in range(width + 1):\n",
    "            new_lat = left.add(diff_lat)\n",
    "            new_lon = top.subtract(diff_lon)\n",
    "            \n",
    "            square = ee.Geometry.Polygon(\n",
    "                [[[left, new_lon],\n",
    "                  [new_lat, new_lon],\n",
    "                  [new_lat, top],\n",
    "                  [left, top]]])\n",
    "            \n",
    "            segments.append(square)\n",
    "            \n",
    "            left = new_lat\n",
    "        top = new_lon\n",
    "        \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2da9b5-925a-4889-a827-03726e45af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "squares = create_segments(bounding_box, new_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43557ff-63f8-4884-88ff-923af7242c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "print(len(squares))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d25f25c-464c-445f-9407-56a73cda4f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22950\n"
     ]
    }
   ],
   "source": [
    "print(np.size(ex[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "854ebb89-37e8-495d-b9e0-02f5b78235d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results(feature):\n",
    "    coords = ee.List(feature.geometry().coordinates().get(0))\n",
    "    lon_min = ee.List(coords.get(0)).get(0)\n",
    "    lon_max = ee.List(coords.get(1)).get(0)\n",
    "    lat_min = ee.List(coords.get(0)).get(1)\n",
    "    lat_max = ee.List(coords.get(2)).get(1)\n",
    "    row = ee.Array([lon_min, \n",
    "                   lat_min, \n",
    "                   lon_max,\n",
    "                   lat_max])\n",
    "    new_feature = ee.Feature(None, {'info': row})\n",
    "    return new_feature\n",
    "\n",
    "# Calculate values for 250m x 250m squares\n",
    "regions = create_segments(bounding_box, new_res)\n",
    "segments = ee.FeatureCollection(regions)\n",
    "\n",
    "# Create above array for each segment, and transform into format that can be written to a CSV file\n",
    "data_set = segments.map(create_results)\n",
    "data_set2 = data_set.aggregate_array('info')\n",
    "data_set3 = data_set2.getInfo() # <- slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c54ecbf2-543c-48a4-9be1-0e3f3c1600e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n"
     ]
    }
   ],
   "source": [
    "print(len(data_set3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d8915f-edda-4d08-b3ef-68eb95aaa65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV and add header & data\n",
    "with open('squares_mine.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    #writer.writerow(header_list)\n",
    "    writer.writerows(data_set3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b33ec6-a4b3-4370-a852-37e1b6219011",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('squares_mine.csv', 'r') as r, \\\n",
    "        open('200m_mine.csv', 'w', newline='') as w:\n",
    "    # Create a csv.reader object from the input file object\n",
    "    csv_reader = csv.reader(r)\n",
    "    # Create a csv.writer object from the output file object\n",
    "    csv_writer = csv.writer(w)\n",
    "    # Add passing rows to new file\n",
    "    # header_list = ['Mininum Longitude', 'Minimum Latitude', 'Maximum Longitude', 'Maximum Latitude', 'Percent Vegetation Loss', \\\n",
    "    #                'Percent Bare Initial','Percent Significant VH Values', 'Average NIR/G', 'Average SWIR1/B', 'NASADEM Elevation', \\\n",
    "    #                'GEDI Elevation','GEDI-SRTM Elevation','GEDI Quality Flag', 'B5', 'B6', 'NDMI', 'Center Lon', \\\n",
    "    #                'Center Lat','Elevation Score', 'Band Variation Score']\n",
    "    header_list = ['Mininum Longitude', 'Minimum Latitude', 'Maximum Longitude', 'Maximum Latitude', 'Number of small squares', \\\n",
    "                   'Percent Vegetation Loss', 'Percent Bare Initial','Percent Significant VH Values', 'Average NIR/G', 'Average SWIR1/B', \\\n",
    "                   'Elevation Score', 'Band Variation Score']\n",
    "    csv_writer.writerow(header_list)\n",
    "    for row in csv_reader:\n",
    "        min_lon = row[0]\n",
    "        min_lat = row[1]\n",
    "        max_lon = row[2]\n",
    "        max_lat = row[3]\n",
    "        squares = []\n",
    "        for row2 in ex:\n",
    "            if float(row2[0]) >= float(min_lon) and float(row2[1]) >= float(min_lat) \\\n",
    "                and float(row2[2]) <= float(max_lon) and float(row2[3]) <= float(max_lat):\n",
    "                squares.append([row2])\n",
    "                \n",
    "        #print(squares)\n",
    "        percent_veg_total = 0\n",
    "        percent_bare_total = 0\n",
    "        percent_sar_total = 0\n",
    "        gndvi_total = 0\n",
    "        swirb_total = 0\n",
    "        elev_score_total = 0\n",
    "        band_score_total = 0\n",
    "        num = 0\n",
    "        for x in squares:\n",
    "            percent_veg_total = percent_veg_total + x[0][4]\n",
    "            percent_bare_total = percent_bare_total + x[0][5]\n",
    "            percent_sar_total = percent_sar_total + x[0][6]\n",
    "            gndvi_total = gndvi_total + x[0][7]\n",
    "            swirb_total = swirb_total + x[0][8]\n",
    "            elev_score_total = elev_score_total + x[0][18] #17 without NDMI\n",
    "            band_score_total = band_score_total + x[0][19] #18 without NDMI\n",
    "            num = num+1\n",
    "        if num >0:\n",
    "            avg_veg = percent_veg_total/num\n",
    "            avg_bare = percent_bare_total/num\n",
    "            avg_sar = percent_sar_total/num\n",
    "            avg_gndvi = gndvi_total/num\n",
    "            avg_swirb = swirb_total/num\n",
    "            avg_elev_score = elev_score_total/num\n",
    "            avg_band_score = band_score_total/num\n",
    "        else: \n",
    "            avg_veg = -999\n",
    "            avg_bare = -999\n",
    "            avg_sar = -999\n",
    "            avg_gndvi = -999\n",
    "            avg_swirb = -999\n",
    "            avg_elev_score = -999\n",
    "            avg_band_score = -999\n",
    "        new_row = [min_lon, min_lat, max_lon, max_lat, num, avg_veg, avg_bare, avg_sar, avg_gndvi, avg_swirb, avg_elev_score, avg_band_score]\n",
    "        csv_writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58110a75-c426-4c24-9a0f-8a0eabe9dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given CSV file of region coordinates and test values, calculate and document whether this region may be a mining location\n",
    "# All results will be saved in \"[file_name]_status.csv\"\n",
    "# Passing region results only will be saved in \"[file_name]_status_passing.csv\"\n",
    "\n",
    "# Open the input file in read mode and output file in write mode\n",
    "with open('200m_mine.csv', 'r') as read_obj, \\\n",
    "        open('200m_mine_status.csv', 'w', newline='') as write_obj:\n",
    "    # Create a csv.reader object from the input file object\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "    next(csv_reader) # skip header\n",
    "    # Create a csv.writer object from the output file object\n",
    "    csv_writer = csv.writer(write_obj)\n",
    "    # Add header to output file, with status column\n",
    "    header_list = ['Mininum Longitude', 'Minimum Latitude', 'Maximum Longitude', 'Maximum Latitude', 'Number of small squares', \\\n",
    "                   'Percent Vegetation Loss', 'Percent Bare Initial','Percent Significant VH Values', 'Average NIR/G', 'Average SWIR1/B', \\\n",
    "                   'Elevation Score', 'Band Variation Score']\n",
    "    csv_writer.writerow(header_list)\n",
    "    # Read each row of the input csv file as list\n",
    "    for row in csv_reader:\n",
    "        \"\"\"\n",
    "        Calculate Status and append to the end of the row/list\n",
    "        Passing Criteria:\n",
    "        If Vegetation Loss < 20% and Bare Earth > 20%: \n",
    "            SAR VH > 25% and NIR/G <= 0.3 and SWIR1/B < 0.65 and Elevation Score >= 5 and B5/B6 Score >= 4\n",
    "        Else: \n",
    "            Vegetation Loss > 20% and SAR VH > 25% and NIR/G <= 0.3 and SWIR1/B < 0.65\n",
    "        \"\"\"\n",
    "        vegetation_loss = float(row[5])\n",
    "        percent_bare = float(row[6])\n",
    "        sar_vh = float(row[7])\n",
    "        nir_g = float(row[8])\n",
    "        swir1_b = float(row[9])\n",
    "        elevation_score = float(row[10])\n",
    "        b5_b6_score = float(row[11])\n",
    "        \n",
    "        if vegetation_loss == -999:\n",
    "            status = 0\n",
    "        elif vegetation_loss < 20 and percent_bare > 20:\n",
    "            status = sar_vh > 25 and nir_g <= 0.3 and swir1_b < 0.65 and elevation_score >= 5 and b5_b6_score >= 4\n",
    "        else: \n",
    "            status = vegetation_loss > 20 and sar_vh > 25 and nir_g <= 0.3 and swir1_b < 0.65\n",
    "\n",
    "        if status:\n",
    "            row.append('Pass')\n",
    "        else: \n",
    "            row.append('Fail')\n",
    "        # Add the updated row / list to the output file\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "# Create a file of only passing statuses\n",
    "with open('200m_mine_status.csv', 'r') as r, \\\n",
    "        open('200m_mine_status_passing.csv', 'w', newline='') as w:\n",
    "    # Create a csv.reader object from the input file object\n",
    "    csv_reader = csv.reader(r)\n",
    "    # Create a csv.writer object from the output file object\n",
    "    csv_writer = csv.writer(w)\n",
    "    # Add header to output file, with status column\n",
    "    csv_writer.writerow(header_list)\n",
    "    # Skip Header in input file\n",
    "    header = next(csv_reader)\n",
    "    if header != None:\n",
    "        # Add passing rows to new file\n",
    "        for row in csv_reader:\n",
    "            if row[12] == \"Pass\":\n",
    "                csv_writer.writerow(row)\n",
    "                \n",
    "# Convert to a Feature Collection\n",
    "# Create a list of Geometries for areas that passed as possible mines\n",
    "with open('200m_mine_status_passing.csv', 'r') as r:\n",
    "    csv_reader = csv.reader(r)\n",
    "    # Skip Header in input file\n",
    "    header = next(csv_reader)\n",
    "    region_list = []\n",
    "    if header != None:\n",
    "        # Convert each region to a Geometry and add to a list\n",
    "        for row in csv_reader:\n",
    "            region = ee.Geometry.Polygon([[[float(row[0]), float(row[3])],\n",
    "                      [float(row[0]), float(row[1])],\n",
    "                      [float(row[2]), float(row[1])],\n",
    "                      [float(row[2]), float(row[3])]]])\n",
    "            region_list.append(region)\n",
    "\n",
    "# Wrap geometry list in a Feature Collection\n",
    "fc = ee.FeatureCollection(region_list)\n",
    "\n",
    "# Export the Feature Collection to Google Earth Engine (GEE)\n",
    "task = ee.batch.Export.table.toAsset(**{\n",
    "  'collection': fc,\n",
    "  'description':'compiled_results',\n",
    "  'assetId': 'users/EmilyNason/trying_something_again', # change to your GEE Asset path and a unique name (will not overwrite already existing assets, so old names cannot be reused)\n",
    "});\n",
    "\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098e846-be6e-4f78-928b-eb62b92a0f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
